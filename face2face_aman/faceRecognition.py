# -*- coding: utf-8 -*-
"""faceRecognition.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15uz3PcD0HRoT4EK7r_2CXH_mIRcgCIID
"""

from PIL import Image
import numpy as np

import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense

import numpy as np
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.vgg16 import preprocess_input

import matplotlib.pyplot as plt


from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.layers import Input, Convolution2D, ZeroPadding2D,MaxPooling2D, Flatten, Dense, Dropout, Activation
from PIL import Image
import numpy as np
from tensorflow.keras.preprocessing.image import load_img, save_img, img_to_array
from tensorflow.keras.applications.imagenet_utils import preprocess_input
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt





def create_vgg():
    model = Sequential()
    model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))
    model.add(Convolution2D(64, (3, 3), activation='relu'))
    model.add(ZeroPadding2D((1,1)))
    model.add(Convolution2D(64, (3, 3), activation='relu'))
    model.add(MaxPooling2D((2,2), strides=(2,2)))

    model.add(ZeroPadding2D((1,1)))
    model.add(Convolution2D(128, (3, 3), activation='relu'))
    model.add(ZeroPadding2D((1,1)))
    model.add(Convolution2D(128, (3, 3), activation='relu'))
    model.add(MaxPooling2D((2,2), strides=(2,2)))

    model.add(ZeroPadding2D((1,1)))
    model.add(Convolution2D(256, (3, 3), activation='relu'))
    model.add(ZeroPadding2D((1,1)))
    model.add(Convolution2D(256, (3, 3), activation='relu'))
    model.add(ZeroPadding2D((1,1)))
    model.add(Convolution2D(256, (3, 3), activation='relu'))
    model.add(MaxPooling2D((2,2), strides=(2,2)))

    model.add(ZeroPadding2D((1,1)))
    model.add(Convolution2D(512, (3, 3), activation='relu'))
    model.add(ZeroPadding2D((1,1)))
    model.add(Convolution2D(512, (3, 3), activation='relu'))
    model.add(ZeroPadding2D((1,1)))
    model.add(Convolution2D(512, (3, 3), activation='relu'))
    model.add(MaxPooling2D((2,2), strides=(2,2)))

    model.add(ZeroPadding2D((1,1)))
    model.add(Convolution2D(512, (3, 3), activation='relu'))
    model.add(ZeroPadding2D((1,1)))
    model.add(Convolution2D(512, (3, 3), activation='relu'))
    model.add(ZeroPadding2D((1,1)))
    model.add(Convolution2D(512, (3, 3), activation='relu'))
    model.add(MaxPooling2D((2,2), strides=(2,2)))

    model.add(Convolution2D(4096, (7, 7), activation='relu'))
    model.add(Dropout(0.5))
    model.add(Convolution2D(4096, (1, 1), activation='relu'))
    model.add(Dropout(0.5))
    model.add(Convolution2D(2622, (1, 1)))
    model.add(Flatten())
    model.add(Activation('softmax'))

    weights_path = './vgg_face_weights.h5'
    model.load_weights(weights_path)

    # model.summary()

    return model




def preprocess_face(image_path):

    img = image.load_img(image_path, target_size=(224, 224)) 
    img_array = image.img_to_array(img) 
    img_array = np.expand_dims(img_array, axis=0) 
    img_array = preprocess_input(img_array)  
    return img_array

def cosine_similarity(embedding1, embedding2):

    dot_product = np.dot(embedding1, embedding2.T)  
    norm1 = np.linalg.norm(embedding1)  
    norm2 = np.linalg.norm(embedding2)  
    return dot_product / (norm1 * norm2)



def show_img(img_array):
    
    img_array = np.squeeze(img_array, axis=0)

    
    img_array += [103.939, 116.779, 123.68]  
    img_array = img_array[:, :, ::-1]  

    img_array = np.clip(img_array, 0, 255).astype('uint8')

    plt.imshow(img_array)
    plt.show()


def show_faces(img1, img2, similarity):
    
    img1 = np.squeeze(img1, axis=0)
    img1 += [103.939, 116.779, 123.68]  
    img1 = img1[:, :, ::-1]  
    img1 = np.clip(img1, 0, 255).astype('uint8')


    img2 = np.squeeze(img2, axis=0)
    img2 += [103.939, 116.779, 123.68]  
    img2 = img2[:, :, ::-1]  
    img2 = np.clip(img2, 0, 255).astype('uint8')

    # fig, axes = plt.subplots(1, 2, figsize=(10, 5))
    fig, axes = plt.subplots(1, 2, figsize=(16, 8))

    axes[0].imshow(img1)
    axes[0].axis('off')

    axes[1].imshow(img2)
    axes[1].axis('off')

    plt.tight_layout()
    plt.title("similarity = {}".format(similarity))
    plt.show()



def find_similarity(img1, img2):
    
    model = create_vgg()
    vgg_face_descriptor = Model(inputs=model.layers[0].input,outputs=model.layers[-2].output)

    face1 = preprocess_face(img1)  
    face2 = preprocess_face(img2)

    embedding1 = vgg_face_descriptor.predict(face1)
    embedding2 = vgg_face_descriptor.predict(face2)

    similarity = cosine_similarity(embedding1, embedding2)

    print("similaraity value :", similarity[0][0])

    show_faces(face1, face2, similarity[0][0])
    
    return similarity[0][0]





# vgg_face_descriptor = Model(inputs=model.layers[0].input,outputs=model.layers[-2].output)
# face1 = preprocess_face('./original.jpg')  
# face2 = preprocess_face('./face_1.jpg') 
# embedding1 = vgg_face_descriptor.predict(face1)
# embedding2 = vgg_face_descriptor.predict(face2)
# similarity = cosine_similarity(embedding1, embedding2)
# print("Cosine Similarity:", similarity[0][0]) 

# show_img(face1)
# show_img(face2)



